# Qianfan-VL：领域增强的通用视觉语言大模型

通过持续预训练实现领域能力增强 | 3B到70B参数规模 | 文档理解与OCR增强 | 推理能力支持

发布时间：2025年8月 | 百度智能云千帆大模型平台

## 目录

### 1. 核心功能
   - 1.1 多尺度模型
   - 1.2 OCR与文档理解
   - 1.3 思考推理

### 2. 架构与技术特色
   - 2.1 整体架构
   - 2.2 技术创新
      - 训练管线
      - 数据合成
      - 昆仑芯训练

### 3. 场景案例展示
   - 3.1 OCR识别
   - 3.2 数学推理
   - 3.3 文档理解
   - 3.4 图表分析
   - 3.5 视频理解

### 4. 快速开始
   - 4.1 安装
   - 4.2 示例代码
   - 4.3 API参数

### 5. 总结

## 核心功能

Qianfan-VL模型系列是面向企业级多模态应用增强的通用多模态大模型，在具备基础通用能力的同时，针对产业化部署的高频场景提供深度优化。通过三大核心功能，精准满足不同场景下的多模态理解需求。

### 多尺度模型

提供3B、8B、70B三种模型变体，满足不同场景需求

### OCR与文档理解增强

全场景OCR识别与智能理解能力，覆盖文档、自然场景和各类应用场景

### 思考推理能力

支持思考链能力，在数学、推理计算等复杂场景展现优异表现

## 多尺度模型满足不同场景需求

提供3B、8B、70B三种模型变体，让不同规模的企业和开发者都能找到合适的解决方案

| 模型名称 | 上下文长度 | 推理支持 | 应用场景 |
|---------|-----------|---------|---------|
| **Qianfan-VL-3B** | 32k | 不支持 | 边缘端实时场景，OCR文字识别 |
| **Qianfan-VL-8B** | 32k | 支持 | 服务端通用场景，微调优化场景 |
| **Qianfan-VL-70B** | 32k | 支持 | 离线数据合成，复杂推理计算场景 |

### 通用能力基准测试表现

在通用多模态基准测试中，Qianfan-VL各尺寸模型与主流模型的全面对比

| 基准测试 | Qianfan-VL-3B | Qianfan-VL-8B | Qianfan-VL-70B | Intern2.5-VL-8B | Intern2.5-VL-78B | Intern3-VL-8B | Intern3-VL-78B | Qwen2.5-VL-7B | Qwen2.5-VL-72B | GPT4.1 | Claude-Sonnet-3.7 |
|---------|---------------|---------------|----------------|-----------------|------------------|---------------|----------------|---------------|----------------|--------|-------------------|
| A-Bench_VAL | 74.25 | 75.65 | **79.15** | 76.91 | 76.14 | 75.86 | 75.86 | 76.49 | **79.22** | 70.75 | 67.04 |
| CCBench | 66.27 | 70 | 77.65 | **78.43** | 71.37 | **77.84** | 70.76 | 57.65 | 73.73 | 27.25 | 19.8 |
| SEEDBench_IMG | 75.74 | 78.21 | **78.85** | 77.17 | 77.15 | 77.00 | 77.52 | 76.98 | **78.34** | 69.98 | 71.18 |
| SEEDBench2_Plus | 68.25 | 70.53 | 71.37 | 69.52 | 69.26 | 69.52 | 68.47 | 70.93 | **73.25** | 65.13 | 60.21 |
| MMVet | 47.25 | 54.13 | 56.42 | 65.14 | 69.72 | **80.28** | **78.90** | 70.64 | 75.69 | 56.88 | 69.72 |
| ScienceQA_TEST | 95.24 | **98.17** | **98.17** | 98.07 | 97.72 | 97.97 | 97.17 | 85.47 | 92.51 | 76.2 | 70.65 |
| ScienceQA_VAL | 94.71 | 97.38 | **98.28** | 97.42 | 96.14 | **97.81** | 95.14 | 83.59 | 91.32 | 74.73 | 69.05 |
| MMT-Bench_VAL | 61.21 | 63.83 | 69.17 | 62.49 | 65.14 | 65.17 | 63.67 | 61.40 | **69.49** | 49.25 | 53.95 |
| MTVQA_TEST | 26.95 | 30.17 | 31.03 | 27.71 | 30.70 | 30.30 | 27.62 | 29.08 | **31.48** | 27.15 | **34.95** |
| BLINK | 51.08 | 56.23 | 58.34 | 54.44 | 53.34 | 55.87 | 51.87 | 54.55 | **63.02** | 40.14 | 43.4 |
| MMStar | 59.07 | 67.4 | **69.07** | 62.86 | 64.13 | **68.40** | 66.07 | 61.53 | 66.00 | 45.47 | 51.53 |
| RealWorldQA | 64.97 | 70.98 | 71.76 | 69.41 | **74.12** | 71.11 | **74.25** | 69.28 | 73.86 | 61.31 | 60.65 |
| Q-Bench1_VAL | 72.57 | 75.99 | **78.33** | 73.90 | 74.98 | 75.99 | 77.99 | 78.10 | **79.93** | 70.43 | 74.25 |
| POPE | 85.15 | 86.84 | 88.79 | 89.06 | 87.14 | **90.59** | 88.87 | 85.97 | 83.35 | 82.15 | 82.07 |

## OCR与文档理解增强

针对两大特色能力进行深度优化：全场景OCR识别和复杂版面文档理解，在多项基准测试中展现卓越性能，为企业级应用提供高精度的视觉理解解决方案

### 全场景OCR任务
- **手写体识别：** 中英文手写体识别，支持草书、楷书等多种字体
- **公式识别：** 数学公式的精准识别与LaTeX格式转换
- **自然场景文字识别：** 街景、招牌、路标等复杂环境下的文字检测
- **卡证信息提取：** 身份证、驾驶证、营业执照等结构化信息提取

### 复杂版面文档理解
- **版面分析：** 自动识别标题、段落、图表、表格等版面元素
- **表格理解：** 复杂表格结构解析，支持合并单元格和多级表头
- **图表理解：** 柱状图、折线图、饼图等数据提取与分析
- **文档问答：** 基于文档内容的智能问答和信息检索
- **文档解析：** PDF、Word等格式文档的结构化解析

### OCR与文档理解基准测试表现

在OCR与文档理解专业基准测试中，Qianfan-VL各尺寸模型与主流模型的全面对比

| 基准测试 | Qianfan-VL-3B | Qianfan-VL-8B | Qianfan-VL-70B | Qwen2.5-VL-3B | Intern2.5-VL-8B | Intern2.5-VL-78B | Intern3-VL-8B | Intern3-VL-78B | Qwen2.5-VL-7B | Qwen2.5-VL-72B | GPT4.1 | Claude-Sonnet-3.7 |
|---------|---------------|---------------|----------------|---------------|-----------------|------------------|---------------|----------------|---------------|----------------|-------------------|
| OCRBench | 834 | 852 | 847 | 810 | 822 | 822 | **881** | 847 | **883** | 874 | 702 | 731 |
| AI2D_TEST | 81.76 | 85.33 | **86.76** | 77.07 | 84.391 | 83.48 | **85.07** | 83.55 | 80.472 | 83.84 | 65.12 | 60.75 |
| OCRVQA_TEST | 66.5 | 69.14 | **72.56** | 69.24 | 30.85 | 43.32 | 39.03 | 35.58 | **71.02** | 66.8 | 38.28 | 26.79 |
| TextVQA_VAL | 79.67 | 82.42 | 82.97 | 79.09 | 78.96 | **84.27** | 82.15 | 83.52 | **84.962** | 83.26 | 61.37 | 61.2 |
| DocVQA_VAL | 90.47 | **94.13** | 93.63 | 92.71 | 92 | 93.59 | 92.04 | 83.82 | 94.91 | **95.75** | 76.13 | 78.75 |
| ChartQA_TEST | 81.76 | **88** | **88** | 83.4 | 83.32 | 85.32 | 85.76 | 82.04 | 86.68 | 87.16 | 31.2 | 23.96 |
| CharXiv_DQ | 90.88 | **94.98** | **96.38** | 79.22 | 73.85 | 83.92 | 75.7 | 84.9 | 78.6 | 88.48 | 73.7 | 90.7 |
| CharXiv_RQ | 66.9 | **90.8** | **97.4** | 33 | 37.4 | 40.9 | 40.2 | 40.3 | 44.2 | 50.1 | 46.4 | 68.4 |

## 思考推理能力

8B和70B模型支持通过特殊token激活思考链能力，覆盖复杂图表理解、视觉推理、数学解题等多种场景。这些任务通常需要基于视觉信息和外部知识进行组合推理，我们通过合成大量视觉/文本推理数据并融入Qianfan-VL的后训练，benchmark显示在推理和计算相关任务上的性能有了显著提升

### 核心推理应用场景

#### 复杂图表理解与推理
- **数据分析：** 从复杂图表中提取关键信息进行推理分析
- **趋势预测：** 基于历史数据图表进行趋势判断和预测
- **关联推理：** 多图表数据的交叉分析和关联推理
- **统计计算：** 图表数据的统计分析和定量计算

#### 数学解题与视觉推理
- **几何推理：** 空间图形关系理解与定理应用
- **公式识别：** 复杂数学公式的精准识别与理解
- **步骤展示：** 清晰的解题过程与步骤呈现
- **逻辑推断：** 基于视觉线索的逻辑推理与问题求解

### 数学解题基准测试表现

| 基准测试 | Qianfan-VL-8B | Qianfan-VL-70B | Intern2.5-VL-8B | Intern2.5-VL-78B | Intern3-VL-8B | Intern3-VL-78B | Qwen2.5-VL-7B | Qwen2.5-VL-72B | GPT4.1 | Claude-Sonnet-3.7 |
|---------|---------------|----------------|-----------------|------------------|---------------|----------------|---------------|----------------|--------|-------------------|
| MathVista-mini | 69.5 | **75.5** | 69.5 | 71.1 | 69.5 | 70.1 | 67.20 | 73.9 | 54.60 | 72.20 |
| MathVision | 27.46 | **45.52** | 21.48 | 33.48 | 29.61 | 34.8 | 25.95 | 39.34 | 34.37 | 43.91 |
| MathVerse | 44.7 | **57.34** | 30.96 | 43.32 | 43.68 | 49.26 | 44.21 | 55.18 | 41.98 | 50.56 |
| ChartQA_Pro | 50.52 | **51.36** | 19.38 | 47.92 | 37.32 | 44.43 | 43.73 | 45.3 | 35.99 | 46.13 |
| HallusionBench | 49.1 | **54.1** | 49.7 | 40.5 | 49.2 | 40.2 | 47.9 | 49.9 | 29.49 | 36.5 |
| InHouse Dataset A | 48.78 | **59.28** | 26 | 43.40 | 40.64 | 41.47 | 45.58 | 57.20 | 21.62 | 42.90 |
| InHouse Dataset B | 61.85 | **65.83** | 26.81 | 39.7 | 36.25 | 42.65 | 30.62 | 59.68 | 15.05 | 24.91 |

## 模型架构设计与技术特色

通过先进的多模态架构设计和三大技术创新，Qianfan-VL实现了领域增强的通用视觉语言能力

### 整体架构

Qianfan-VL采用先进的多模态架构，融合了业界最佳实践和自主创新

![Qianfan-VL架构图](images/qianfan_vl_arch_professional.svg)

#### 核心架构组件

**语言模型**
基于Llama 3.1架构，通过词表扩充和本地化增强3T中英文语料，支持中英文混合理解

**视觉编码器**
采用InternViT初始化，支持不同分辨率图像的动态分块，最高支持4K分辨率输入

**跨模态融合**
MLP适配器实现视觉与语言模态的无缝桥接，确保信息传递的准确性和效率

## 技术创新与特色

### 能力增强训练管线
创新的四阶段训练策略，在保持通用能力基础上实现领域能力显著提升

### 高精度数据合成技术
结合传统CV模型与程序化生成，高效构建高质量训练数据

### 大规模昆仑芯训练
全程使用百度自研昆仑P800芯片完成训练，展现国产AI基础设施成熟能力

## 能力增强训练管线

创新的四阶段渐进式训练策略，在保持通用能力的基础上实现领域能力的显著提升

![训练管线图](images/training_pipeline_professional.svg)

**Stage 1：跨模态对齐** - 该阶段旨在建立视觉-语言基础连接映射，采用仅更新MLP Adapter、冻结Vision Encoder和LLM的训练策略，使用100B tokens通用知识数据进行训练。这一阶段是必要的，否则会影响整体性能。

**Stage 2：通用知识注入** - 重点关注注入的数据量，尽量覆盖所有训练数据，采用全参数更新训练策略，使用3.5T tokens通用知识数据。该阶段建立模型的强大基础能力，同时放入足够比例的文本语料防止LLM知识被灾难性遗忘。

**Stage 3：领域增强知识注入** - 精选要增强领域的高质量数据，包含所增强领域的任务数据，同时融合通用数据采样以维持通用知识、防止灾难性遗忘，采用全参数更新训练，使用300B tokens领域特定数据和通用采样数据。该阶段实现专业能力的显著提升。

**Stage 4：后训练** - 该阶段旨在提升指令跟随能力和偏好对齐，采用全参数更新训练策略，使用1B tokens指令微调数据进行训练。会使用高质量的对齐数据，包括复杂指令跟随、写作、问答、编程、OCR、信息抽取、数学、推理计算等任务，同时放入足量的纯文本指令微调数据，维持文本模型的能力。

## 高精度数据合成技术

构建面向多模态任务的大规模数据合成管线，涵盖文档识别、数学解题、图表理解、表格识别、公式识别、自然场景OCR等核心任务，通过精细化的pipeline设计和中间过程数据构造，实现高质量训练数据的规模化生产

### 多任务数据合成管线

#### 文档识别OCR管线
**核心任务：** 全方位解析、图像转Markdown、文档问答三大功能
- **全方位解析：** 融合版面、类别、内容的多维度分析，支持多语言和手写扫描文档
- **图像转Markdown：** 单页/多页文档高效转换为结构化Markdown
- **文档问答：** 支持摘要、推理、多轮对话的深度理解
- **数据源：** DocVQA/DocReason25K等开源+自有合成和二次增强
- **鲁棒性增强：** 通过位图化、腐蚀膨胀、高斯模糊等模拟真实噪声

合成规模：450M样本 | 质量循环：多VLM交叉验证

#### 数学解题OCR管线
**核心优势：** 教育数据定制化构建+视觉数学推理增强
- **教育数据预处理：** 针对教育场景收集多语言高质量解题数据，进行术语和符号标准化，构建问题/条件/步骤/公式的结构化表达，形成教育场景数据源
- **解题数据合成：** 结合知识体系，通过结构化表达→LaTeX→HTML→图像的pipeline合成拍照解题场景数据
- **视觉提取增强：** 针对图表、公式、几何等复杂场景，通过Markdown、LaTeX、Asymptote等形式化描述语言结合HTML渲染构建高质量数据
- **多样场景合成：** 通过多种手写风格和纸张背景渲染进行数据增强，构建从K12到大学难度的多场景多层级数据
- **严格质量验证：** 通过基于规则的过滤、拒绝采样、多模型投票、OCR逐字段回读等方式验证，确保数据质量

合成规模：85M题目 | 覆盖：K12到大学全谱系 | 质量保证：多重验证机制

#### 图表理解管线
**核心目标：** 自动生成高质量图表问答对，覆盖数据检索、视觉属性、计算问答
- **数据扩充：** 开源数据集采样+百度图片搜索API扩充+去重处理
- **图表摘要：** 预训练VLM生成含视觉和数值信息的结构化摘要
- **两阶段生成：** 基于摘要生成问题→基于问题和摘要生成答案
- **LaTeX渲染：** Arxiv数据爬取+正则提取+TexLive重新渲染精准描述
- **质量控制：** 思考模型质量检查+人工复核双重保障

合成规模：180M图表 | 问题类型：数据检索+视觉属性+计算问答

#### 表格识别管线
**核心任务：** 表格结构识别与表格问答
- **表格结构化：** 图像表格精准恢复为HTML/LaTeX，支持无边框表、合同表等复杂版式
- **表格问答：** 基于表格图像的数值计算、对比分析、信息检索
- **内容生成：** 随机表格结构(3-20行/列)+Faker库/LLM填充+随机单元格合并
- **图像渲染：** 50+专业CSS主题(统计报表/技术文档)+Jinja2+KaTeX引擎
- **数据增强：** 几何变换+颜色扰动+模糊处理丰富多样性

合成规模：120M表格 | 数据源：TabMWP+MMC-Inst+BigDocs+自有合成

#### 公式识别管线
**核心能力：** 融合符号识别+语法解析+语义理解
- **符号识别：** 数学符号、希腊字母、特殊记号精准识别
- **结构解析：** 分式、根式、上下标、矩阵等复杂结构
- **语义理解：** 公式语义与数学概念的关联映射
- **多引擎渲染：** MathJax/KaTeX确保渲染一致性
- **手写模拟：** 多样化手写特征+纸张纹理+噪声干扰

合成规模：95M公式 | 支持：代数+几何+微积分+线性代数全覆盖

#### 自然场景OCR管线
**核心创新：** Synthtext-pipeline系统化文本图像合成方法
- **背景筛选：** 轻量级OCR模型+图像类型检测剔除含文本/非静态样本
- **场景理解：** 语义分割模型+单目深度估计获取区域划分与3D结构
- **真实投影：** 平面检测+透视投影+随机文本样式自然投影
- **融合增强：** Poisson融合确保遮挡、阴影、纹理一致性

合成规模：320M场景 | 标注精度：字符级+单词级bounding box

## 大规模昆仑芯并行训练

基于百度自研昆仑P800芯片，构建了业界领先的超大规模分布式训练系统，通过创新的并行策略和算子优化实现高效训练

### 集群规模与数据规模
- **集群规模：** 5000+ 昆仑P800并行
- **训练数据规模：** 3.5T Token训练数据
- **规模化效率：** 90%+ 大规模集群扩展效率

### 3D并行训练策略
采用数据并行(DP)、张量并行(TP)、流水线并行(PP)相结合，根据模型层特性动态负载均衡优化分配。梯度同步优化减少60% AllReduce通信时间，结合ZeRO-3状态分片技术内存优化。流水线调度采用1F1B策略，bubble率控制在5%以内，序列维度分片使长序列训练内存减半，动态批处理根据序列长度自适应调整batch size，选择性激活重计算checkpoint优化。

### 昆仑芯通算融合技术
**架构优势：** P800架构中，通信算子和矩阵乘法算子归属于不同的硬件单元，与传统GPGPU架构形成显著差异。在传统GPU架构中，通信和计算往往竞争相同的硬件资源，导致执行时相互阻塞。P800架构通过专用通信处理单元和矩阵乘法处理单元的硬件分离设计，实现了真正的通算并行。这种设计带来的核心优势是资源隔离，通信算子执行完全不受矩阵乘法算子影响，避免了传统架构中的资源竞争。同时通过并行执行机制，数据传输和矩阵运算可以同时进行，大幅提升硬件利用率。更重要的是，这种架构可以使用overlap技术，将通信延迟与计算过程相互掩盖。

**GEMM通算融合技术：** 通过建立额外的旁路流(BypassStream)，可以将通信算子无缝嵌入到矩阵乘法操作的前后。这种机制的核心思想是建立独立的调度系统，旁路流独立于主计算流运行，不会阻塞主矩阵乘法流水线。同时通过数据预取机制，提前发起数据通信，确保计算所需数据及时到达。计算完成后立即发起结果通信传输，形成完整的流水线。

**多流优化实现：** 以AllGather与矩阵乘法融合为例，通过精细的数据分块策略，实现计算与通信的深度融合。传统方法需要先完成整个AllGather操作，等待所有数据传输完成后才能开始GEMM计算。而融合方法将数据拆分成多个块，每个数据块在通信完成后立即开始对应的计算，形成流水线并行。当通信算子准备好原子数据块时，矩阵乘法即可立即开始运算，无需等待所有数据准备完毕，实现了真正的流水线并行。

## 场景案例展示

### OCR识别

#### 手写文字识别
用户：识别图中的文字
Qianfan-VL：征衣未解再跨鞍，接续奋斗开新局。中国青年作为中国大厦的不朽钢钉，中国革命的燎原火种，中国故事的青春注脚，接过时代的话筒，当有对答世界的音量，让中国声音燎亮东方。奋斗圆梦，再谱华章！

#### 场景文字识别
用户：请识别图中的文字
Qianfan-VL：实景现房中赫出品
颐和园公园南门800米/北侧距万柳高尔夫80米
心30米/距地铁巴沟站C出口10米
T·6271

#### 发票信息提取
用户：提取发票信息
Qianfan-VL：
```json
{
  "发票号码": "0110020001",
  "开票日期": "2021年10月",
  "合计": "1565.05",
  "价税合计": "1580.70",
  "项目列表": [
    {"项目名称": "成药*安宫牛黄丸", "数量": "1", "金额": "749.11"},
    {"项目名称": "成药*益安宁丸", "数量": "1", "金额": "758.71"},
    {"项目名称": "学药品制剂*藿香正气软胶囊", "数量": "2", "金额": "57.23"}
  ]
}
```

### 数学推理

详细的几何题解题过程和二次函数问题求解示例（包含完整的推理步骤和验证）

### 文档理解

#### 文档内容理解
用户：根据文档内容，银监会在文件中对商业房地产信贷提出了哪些具体管理要求？这些要求对银行风险控制有什么影响？
Qianfan-VL：文件提出四项核心要求：1）严格管理房地产开发贷款，限制资金流向不合规项目；2）规范土地储备贷款，限定贷款比例和期限；3）加强住房消费贷款管理，实施差异化首付比例和利率；4）严控商用房贷款。这些要求通过限制资金过度流入房地产、提高贷款门槛、实施差异化定价等手段，有效降低银行信贷风险，防范房地产泡沫。

#### 表格结构理解
支持复杂表格的HTML解析和结构化提取

### 图表分析

#### 图表数据分析
基于图表内容进行趋势分析、数据提取和推理判断

#### 股票走势分析
对上证指数等金融图表进行专业分析和趋势描述

### 视频理解
对视频内容进行描述和理解，包括场景识别、动作理解等

## 快速开始

### 安装与配置

安装OpenAI SDK以在千帆大模型平台使用Qianfan-VL系列模型：

```bash
pip install openai
```

### 功能示例代码

#### OCR文字识别

```python
from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://qianfan.baidubce.com/v2",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# 读取并编码图片
with open("document.jpg", "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

# OCR识别
response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "请识别图片中的所有文字，保持原始格式"},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.1,  # 低温度以提高准确性
    max_tokens = 2048
)

print(response.choices[0].message.content)
```

#### 数学解题

```python
from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://qianfan.baidubce.com/v2",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# 读取数学题图片
with open("math_problem.jpg", "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

# 激活思考链推理进行解题
response = client.chat.completions.create(
    model = "Qianfan-VL-70B",  # 使用大模型以获得更强的推理能力
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text", 
                    "text": """请解答这道数学题：
1. 详细说明解题思路
2. 给出步骤推导过程
3. 数学公式使用LaTeX格式
4. 提供最终答案"""
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.2,
    max_tokens = 4096
)

print(response.choices[0].message.content)
```

#### 文档理解与提取

```python
from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://qianfan.baidubce.com/v2",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# 读取文档图片
with open("contract.jpg", "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

# 文档理解和信息提取
response = client.chat.completions.create(
    model = "Qianfan-VL-8B",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": """分析这份合同文件：
1. 识别文档类型和关键条款
2. 提取双方当事人信息
3. 标注重要日期和金额
4. 识别潜在风险条款
5. 输出为JSON格式"""
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.1,
    max_tokens = 3000
)

import json
result = json.loads(response.choices[0].message.content)
print(json.dumps(result, ensure_ascii=False, indent=2))
```

#### 思考链推理能力

```python
from openai import OpenAI
import base64
import os

client = OpenAI(
    api_key = os.environ.get("QIANFAN_SECRET_KEY"),
    base_url = "https://qianfan.baidubce.com/v2",
    default_headers = {"X-Access-Key": os.environ.get("QIANFAN_ACCESS_KEY")}
)

# 读取复杂图表
with open("complex_chart.jpg", "rb") as image_file:
    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')

# 使用思考链进行深度分析
response = client.chat.completions.create(
    model = "Qianfan-VL-70B",
    messages=[
        {
            "role": "system",
            "content": "你是一个数据分析专家，请使用思考链方法进行分析"
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": """分析这个图表并回答：
1. 数据的整体趋势是什么？
2. 有哪些异常点需要关注？
3. 基于当前数据，未来3个月的预测是什么？
4. 给出你的推理过程和依据"""
                },
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        }
    ],
    temperature = 0.3,
    max_tokens = 2048
)

print(response.choices[0].message.content)
```

### API参数说明

详细的API参数说明和调用文档请参考：[千帆ModelBuilder API文档](https://cloud.baidu.com/doc/qianfan-docs/s/Fm9l6ocai)

## 总结

**Qianfan-VL定位为领域增强的通用多模态大语言模型**，提供3B、8B、70B多种规格，实现多尺寸、全场景应用覆盖。围绕B端客户需求，重点增强了智能办公和K12教育场景的多项任务能力，包括OCR识别、文档解析、拍照解题、图表理解、复杂表格解析等。面对需要复杂推理的场景，可在8B和70B模型上开启思考功能，进一步增强模型效果。

**技术层面采用多阶段渐进式的持续预训练技术**，在维持通用能力的基础上不断增强领域精专数据的配比，进而实现领域能力的显著提升。基于传统小模型和程序化合成的方法，Qianfan-VL团队构建了大量高精度的训练数据，显著提高了长尾场景的数据密度，提升了模型泛化性。所有尺寸模型都在5000+昆仑芯片加持下的大规模并行训练中完成，并且这些模型可在昆仑芯、GPU等芯片上进行高效率推理。

**Qianfan-VL系列模型在各个同尺寸参数量的模型中具备良好的通用性**，并且在精专的领域benchmark上有出色表现，在实际业务的benchmark中表现更佳。通过领域增强技术路线，Qianfan-VL为企业级多模态AI应用提供了兼具通用性和专业性的高性能解决方案。